{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e189201a",
   "metadata": {},
   "source": [
    "### 날씨 데이터 파싱\n",
    "* [기상청날씨데이터](http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp)\n",
    "* 파싱한 데이터를 dict, list 자료구조에 저장\n",
    "* 자료구조의 데이터를 json 파일로 저장\n",
    "* BeautifulSoup 의 find(), find_all(), select(), select_one() 함수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ac3729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lxml\n",
      "Version: 5.2.1\n",
      "Summary: Powerful and Pythonic XML processing library combining libxml2/libxslt with the ElementTree API.\n",
      "Home-page: https://lxml.de/\n",
      "Author: lxml dev team\n",
      "Author-email: lxml-dev@lxml.de\n",
      "License: BSD-3-Clause\n",
      "Location: C:\\Users\\vega2\\anaconda3\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: parsel, Scrapy\n"
     ]
    }
   ],
   "source": [
    "!pip3 show lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26ac35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<class 'bs4.element.Tag'> <title>기상청 육상 중기예보</title> 기상청 육상 중기예보\n",
      "<class 'bs4.element.ResultSet'> [<title>기상청 육상 중기예보</title>, <title>전국 육상 중기예보 - 2024년 07월 24일 (수)요일 18:00 발표</title>, <title>전국 육상중기예보</title>]\n",
      "==find()  <class 'bs4.element.Tag'>\n",
      "==select_one()  <class 'bs4.element.Tag'>\n",
      "==find_all()  <class 'bs4.element.ResultSet'> 41\n",
      "==select()  <class 'bs4.element.ResultSet'>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "\n",
    "res = requests.get(url)\n",
    "print(res.status_code)\n",
    "\n",
    "if res.ok:\n",
    "    soup = BeautifulSoup(res.text, features='xml')\n",
    "    \n",
    "    title_tag = soup.find('title')\n",
    "    print(type(title_tag), title_tag, title_tag.text)\n",
    "    \n",
    "    title_all_tag = soup.find_all('title')\n",
    "    print(type(title_all_tag), title_all_tag)\n",
    "    \n",
    "    location_tag = soup.find('location', attrs={'wl_ver':3})\n",
    "    print('==find() ', type(location_tag))\n",
    "\n",
    "    location_tag2 = soup.select_one(\"location[wl_ver='3']\")\n",
    "    print('==select_one() ',type(location_tag2))\n",
    "\n",
    "    loc_tag_all = soup.findAll('location', attrs={'wl_ver':3})\n",
    "    print('==find_all() ', type(loc_tag_all), len(loc_tag_all))\n",
    "\n",
    "    loc_tag_all2 = soup.select(\"location[wl_ver='3']\")\n",
    "    print('==select() ', type(loc_tag_all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fbb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<class 'bs4.element.Tag'> <title>기상청 육상 중기예보</title> 기상청 육상 중기예보\n",
      "<class 'bs4.element.ResultSet'> [<title>기상청 육상 중기예보</title>, <title>전국 육상 중기예보 - 2024년 08월 06일 (화)요일 06:00 발표</title>, <title>전국 육상중기예보</title>]\n",
      "==find()  <class 'bs4.element.Tag'>\n",
      "==select_one()  <class 'bs4.element.Tag'>\n",
      "==find_all()  <class 'bs4.element.ResultSet'> 41\n",
      "==select()  <class 'bs4.element.ResultSet'>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "\n",
    "res = requests.get(url)\n",
    "print(res.status_code)\n",
    "\n",
    "if res.ok:\n",
    "    soup = BeautifulSoup(res.text, features='xml')\n",
    "    \n",
    "    title_tag = soup.find('title')\n",
    "    print(type(title_tag), title_tag, title_tag.text)\n",
    "    \n",
    "    title_all_tag = soup.find_all('title')\n",
    "    print(type(title_all_tag), title_all_tag)\n",
    "    \n",
    "    location_tag = soup.find('location', attrs={'wl_ver':3})\n",
    "    print('==find() ', type(location_tag))\n",
    "\n",
    "    location_tag2 = soup.select_one(\"location[wl_ver='3']\")\n",
    "    print('==select_one() ',type(location_tag2))\n",
    "\n",
    "    loc_tag_all = soup.findAll('location', attrs={'wl_ver':3})\n",
    "    print('==find_all() ', type(loc_tag_all), len(loc_tag_all))\n",
    "\n",
    "    loc_tag_all2 = soup.select(\"location[wl_ver='3']\")\n",
    "    print('==select() ', type(loc_tag_all2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a274e52",
   "metadata": {},
   "source": [
    "### 서울(city)의 날씨 데이터 Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16ec9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'province': '서울ㆍ인천ㆍ경기도', 'city': '서울', 'datas': [{'mode': 'A02', 'tmEf': '2024-08-09 00:00', 'wf': '구름많음', 'tmn': '26', 'tmx': '34'}, {'mode': 'A02', 'tmEf': '2024-08-09 12:00', 'wf': '맑음', 'tmn': '26', 'tmx': '34'}, {'mode': 'A02', 'tmEf': '2024-08-10 00:00', 'wf': '구름많음', 'tmn': '27', 'tmx': '35'}, {'mode': 'A02', 'tmEf': '2024-08-10 12:00', 'wf': '구름많음', 'tmn': '27', 'tmx': '35'}, {'mode': 'A02', 'tmEf': '2024-08-11 00:00', 'wf': '구름많음', 'tmn': '27', 'tmx': '33'}, {'mode': 'A02', 'tmEf': '2024-08-11 12:00', 'wf': '맑음', 'tmn': '27', 'tmx': '33'}, {'mode': 'A02', 'tmEf': '2024-08-12 00:00', 'wf': '구름많음', 'tmn': '26', 'tmx': '33'}, {'mode': 'A02', 'tmEf': '2024-08-12 12:00', 'wf': '구름많음', 'tmn': '26', 'tmx': '33'}, {'mode': 'A02', 'tmEf': '2024-08-13 00:00', 'wf': '맑음', 'tmn': '26', 'tmx': '33'}, {'mode': 'A02', 'tmEf': '2024-08-13 12:00', 'wf': '구름많음', 'tmn': '26', 'tmx': '33'}, {'mode': 'A01', 'tmEf': '2024-08-14 00:00', 'wf': '구름많음', 'tmn': '27', 'tmx': '34'}, {'mode': 'A01', 'tmEf': '2024-08-15 00:00', 'wf': '구름많음', 'tmn': '26', 'tmx': '33'}, {'mode': 'A01', 'tmEf': '2024-08-16 00:00', 'wf': '맑음', 'tmn': '25', 'tmx': '32'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "res = requests.get(url)\n",
    "if res.ok:\n",
    "    soup = BeautifulSoup(res.text, features='xml')\n",
    "    location_dict = {} #dict()\n",
    "    location_tag = soup.find('location',attrs={'wl_ver':3})\n",
    "    #print(location_tag)\n",
    "    location_dict['province'] = location_tag.find('province').text\n",
    "    location_dict['city'] = location_tag.find('city').text\n",
    "    data_tags = location_tag.findAll('data')\n",
    "    '''\n",
    "    <data>\n",
    "        <mode>A02</mode>\n",
    "        <tmEf>2022-08-28 12:00</tmEf>\n",
    "        <wf>구름많음</wf>\n",
    "        <tmn>18</tmn>\n",
    "        <tmx>28</tmx>\n",
    "        <reliability/>\n",
    "        <rnSt>30</rnSt>\n",
    "    </data>\n",
    "    '''\n",
    "    data_list = [] #[{},{},{}]\n",
    "    for data_tag in data_tags:\n",
    "        data_dict = {}\n",
    "        data_dict['mode'] = data_tag.find('mode').text\n",
    "        data_dict['tmEf'] = data_tag.find('tmEf').text\n",
    "        data_dict['wf'] = data_tag.find('wf').text\n",
    "        data_dict['tmn'] = data_tag.find('tmn').text\n",
    "        data_dict['tmx'] = data_tag.find('tmx').text\n",
    "        data_list.append(data_dict)\n",
    "\n",
    "    location_dict['datas'] = data_list\n",
    "    print(location_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4e0ce9",
   "metadata": {},
   "source": [
    "### 41개 City의  날씨 데이터 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6395c39",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(location_tag)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m location_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovince\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m location_tag\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovince\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 12\u001b[0m location_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m location_tag\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     13\u001b[0m data_tags \u001b[38;5;241m=\u001b[39m location_tag\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m<data>\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    <mode>A02</mode>\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m</data>\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\element.py:2433\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2435\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "\n",
    "res = requests.get(url)\n",
    "if res.ok:\n",
    "    soup = BeautifulSoup(res.text, features=\"xml\")\n",
    "    location_tags = soup.find_all('location', attrs={'wl_ver':3})\n",
    "    # print(len(location_tags))\n",
    "    location_list = list()\n",
    "    \n",
    "    for location_tag in location_tags:    \n",
    "        location_dict = {} #dict()\n",
    "\n",
    "        # \"province\":\"서울ㆍ인천ㆍ경기도\"\n",
    "        location_dict['province'] = location_tag.find('province').text\n",
    "        # 서울\n",
    "        location_dict['city'] = location_tag.find('city').text\n",
    "\n",
    "        data_tags = location_tag.find_all('data')\n",
    "        data_list = []\n",
    "        for data_tag in data_tags:\n",
    "            data_dict = dict()\n",
    "            # {\"mode:\"A02\",\"tmEf\":\"2022-01-31 00:00\",\"wf\":\"맑음\"}\n",
    "            data_dict['mode'] = data_tag.find('mode').text\n",
    "            data_dict['tmEf'] = data_tag.find('tmEf').text\n",
    "            data_dict['wf'] = data_tag.find('wf').text\n",
    "            data_dict['tmn'] = data_tag.find('tmn').text\n",
    "            data_dict['tmx'] = data_tag.find('tmx').text\n",
    "            data_list.append(data_dict)\n",
    "\n",
    "        location_dict['datas'] = data_list\n",
    "        \n",
    "        location_list.append(location_dict)\n",
    "        \n",
    "print(len(location_list))\n",
    "print(location_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735da9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf43b03",
   "metadata": {},
   "source": [
    "#### weather.json 파일로 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebaf9c8",
   "metadata": {},
   "source": [
    "#### weather.json 파일을 읽어오기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
